{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0975667",
   "metadata": {},
   "source": [
    "https://en.seedfinder.eu/database/breeder/\n",
    "\n",
    "Idea: scrapear y obtener los datos de todas las geneticas\n",
    "\n",
    "Idea 2: generar vectores con los datos de cada genetica para calcular los N mas similares a una consulta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eaea5a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\felipe\\miniconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from selenium) (1.26.2)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\felipe\\miniconda3\\lib\\site-packages (3.2.2)\n",
      "Requirement already satisfied: requests in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from webdriver-manager) (2.25.1)\n",
      "Requirement already satisfied: crayons in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from webdriver-manager) (0.4.0)\n",
      "Requirement already satisfied: configparser in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from webdriver-manager) (5.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from crayons->webdriver-manager) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from requests->webdriver-manager) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from requests->webdriver-manager) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from requests->webdriver-manager) (2.10)\n",
      "Collecting en-core-web-sm==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
      "     --------------------------------------- 12.8/12.8 MB 12.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from en-core-web-sm==3.4.0) (3.4.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.7)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.25.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (61.2.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.26.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2020.12.5)\n",
      "Requirement already satisfied: blis<0.10.0,>=0.7.8 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.9.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.1.1)\n",
      "[!] As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the full\n",
      "pipeline package name 'en_core_web_sm' instead.\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Requirement already satisfied: spacy in c:\\users\\felipe\\miniconda3\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy) (1.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy) (3.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy) (1.23.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy) (61.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy) (2.4.4)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy) (8.1.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy) (1.9.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy) (4.1.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.1)\n",
      "Requirement already satisfied: blis<0.10.0,>=0.7.8 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.9.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting thefuzz[speedup]\n",
      "  Downloading thefuzz-0.19.0-py2.py3-none-any.whl (17 kB)\n",
      "Collecting python-levenshtein>=0.12\n",
      "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
      "     ---------------------------------------- 50.5/50.5 kB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: setuptools in c:\\users\\felipe\\miniconda3\\lib\\site-packages (from python-levenshtein>=0.12->thefuzz[speedup]) (61.2.0)\n",
      "Building wheels for collected packages: python-levenshtein\n",
      "  Building wheel for python-levenshtein (setup.py): started\n",
      "  Building wheel for python-levenshtein (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for python-levenshtein\n",
      "Failed to build python-levenshtein\n",
      "Installing collected packages: thefuzz, python-levenshtein\n",
      "  Running setup.py install for python-levenshtein: started\n",
      "  Running setup.py install for python-levenshtein: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [28 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.9\n",
      "  creating build\\lib.win-amd64-3.9\\Levenshtein\n",
      "  copying Levenshtein\\StringMatcher.py -> build\\lib.win-amd64-3.9\\Levenshtein\n",
      "  copying Levenshtein\\__init__.py -> build\\lib.win-amd64-3.9\\Levenshtein\n",
      "  running egg_info\n",
      "  writing python_Levenshtein.egg-info\\PKG-INFO\n",
      "  writing dependency_links to python_Levenshtein.egg-info\\dependency_links.txt\n",
      "  deleting python_Levenshtein.egg-info\\entry_points.txt\n",
      "  writing namespace_packages to python_Levenshtein.egg-info\\namespace_packages.txt\n",
      "  writing requirements to python_Levenshtein.egg-info\\requires.txt\n",
      "  writing top-level names to python_Levenshtein.egg-info\\top_level.txt\n",
      "  reading manifest file 'python_Levenshtein.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no previously-included files matching '*pyc' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*so' found anywhere in distribution\n",
      "  warning: no previously-included files matching '.project' found anywhere in distribution\n",
      "  warning: no previously-included files matching '.pydevproject' found anywhere in distribution\n",
      "  adding license file 'COPYING'\n",
      "  writing manifest file 'python_Levenshtein.egg-info\\SOURCES.txt'\n",
      "  copying Levenshtein\\_levenshtein.c -> build\\lib.win-amd64-3.9\\Levenshtein\n",
      "  copying Levenshtein\\_levenshtein.h -> build\\lib.win-amd64-3.9\\Levenshtein\n",
      "  running build_ext\n",
      "  building 'Levenshtein._levenshtein' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for python-levenshtein\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Running setup.py install for python-levenshtein did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [29 lines of output]\n",
      "  running install\n",
      "  C:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "    warnings.warn(\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.9\n",
      "  creating build\\lib.win-amd64-3.9\\Levenshtein\n",
      "  copying Levenshtein\\StringMatcher.py -> build\\lib.win-amd64-3.9\\Levenshtein\n",
      "  copying Levenshtein\\__init__.py -> build\\lib.win-amd64-3.9\\Levenshtein\n",
      "  running egg_info\n",
      "  writing python_Levenshtein.egg-info\\PKG-INFO\n",
      "  writing dependency_links to python_Levenshtein.egg-info\\dependency_links.txt\n",
      "  writing namespace_packages to python_Levenshtein.egg-info\\namespace_packages.txt\n",
      "  writing requirements to python_Levenshtein.egg-info\\requires.txt\n",
      "  writing top-level names to python_Levenshtein.egg-info\\top_level.txt\n",
      "  reading manifest file 'python_Levenshtein.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no previously-included files matching '*pyc' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*so' found anywhere in distribution\n",
      "  warning: no previously-included files matching '.project' found anywhere in distribution\n",
      "  warning: no previously-included files matching '.pydevproject' found anywhere in distribution\n",
      "  adding license file 'COPYING'\n",
      "  writing manifest file 'python_Levenshtein.egg-info\\SOURCES.txt'\n",
      "  copying Levenshtein\\_levenshtein.c -> build\\lib.win-amd64-3.9\\Levenshtein\n",
      "  copying Levenshtein\\_levenshtein.h -> build\\lib.win-amd64-3.9\\Levenshtein\n",
      "  running build_ext\n",
      "  building 'Levenshtein._levenshtein' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "Encountered error while trying to install package.\n",
      "\n",
      "python-levenshtein\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n",
      "C:\\Users\\Felipe\\miniconda3\\lib\\site-packages\\thefuzz\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "# Installs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "from time import sleep\n",
    "!pip install selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "chrome_options = Options()\n",
    "chrome_options.headless = True\n",
    "!pip install webdriver-manager\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "#Spacy\n",
    "!python -m spacy download en\n",
    "!pip install spacy\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# get_names\n",
    "!pip install thefuzz[speedup]\n",
    "from thefuzz import process, fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe52169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(navegacion_con_headers = False):\n",
    "    os.chdir('C:/Users/Felipe/Desktop/Proyectos/Weed')\n",
    "    \n",
    "    # instanciamos webdriver (True or False)\n",
    "    if navegacion_con_headers == True:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    else:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install(), options=chrome_options)\n",
    "    \n",
    "    # ir a la pagina con bancos de semillas\n",
    "    driver.get('https://en.seedfinder.eu/database/breeder/')\n",
    "    \n",
    "    # Link a todos los bancos de semillas\n",
    "    links_bancos = driver.find_elements('xpath','//*[@id=\"cannabis-breeders-table\"]/li/span[2]/a')\n",
    "    links_bancos = [elem.get_attribute('href') for elem in links_bancos]\n",
    "    \n",
    "    #Iterar por banco\n",
    "    links_geneticas = []\n",
    "    for i,link in enumerate(links_bancos):\n",
    "        driver.get(link)\n",
    "        sleep(5)\n",
    "        geneticas_del_banco = driver.find_elements('xpath','//*[@id=\"TABLE_1\"]/tbody/tr/th/a')\n",
    "        geneticas_del_banco = [elem.get_attribute('href') for elem in geneticas_del_banco]\n",
    "        links_geneticas.extend(geneticas_del_banco)\n",
    "        print(f'\\n\\nIteracion {i} de {len(links_bancos)}\\n{len(geneticas_del_banco)} geneticas encontradas en esta iteracion ({len(links_geneticas)}) en total')\n",
    "        \n",
    "        # Guardado de links de geneticas\n",
    "        results = open('links.txt','w')\n",
    "        for i in links_geneticas:\n",
    "            results.write(str(i))\n",
    "            results.write('\\n')\n",
    "        results.close()\n",
    "        \n",
    "    # leer links\n",
    "    with open('links.txt') as f:\n",
    "        links = f.readlines()\n",
    "\n",
    "    return [l.replace('\\n','') for l in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b21016e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(navegacion_con_headers = False):\n",
    "\n",
    "    # instanciamos webdriver (True or False)\n",
    "    if navegacion_con_headers == True:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    else:\n",
    "        driver = webdriver.Chrome(ChromeDriverManager().install(), options=chrome_options)\n",
    "\n",
    "    #read links\n",
    "    os.chdir('C:/Users/Felipe/Desktop/Proyectos/Weed')\n",
    "    with open('links.txt') as f:\n",
    "        links = f.readlines()\n",
    "    links = [l.replace('\\n','') for l in links]\n",
    "\n",
    "    #Iterate links and scrape\n",
    "    names = []\n",
    "    info = []\n",
    "    images = []\n",
    "\n",
    "    for i, link in enumerate(links): \n",
    "        try:\n",
    "            driver.get(link)\n",
    "            sleep(1.5)\n",
    "            print(f'\\n\\n{i} de {len(links)}:')\n",
    "\n",
    "            # Nombre\n",
    "            try:\n",
    "                name = driver.find_element('xpath','//*/div/h1').text\n",
    "            except:\n",
    "                name = ''\n",
    "\n",
    "            # Info\n",
    "            try:\n",
    "                basic1 = driver.find_element_by_xpath('//*[@id=\"bscinfo\"]').text\n",
    "            except:\n",
    "                basic1 = ''\n",
    "            try:\n",
    "                basic2 = driver.find_element_by_xpath('//*[@id=\"prces\"]/div[2]').text\n",
    "            except:\n",
    "                basic2 = ''\n",
    "\n",
    "            final = basic1 + basic2\n",
    "\n",
    "\n",
    "            # Imagen\n",
    "            try:\n",
    "                imagen = driver.find_element_by_xpath('//*[@id=\"bscinfo\"]/div[2]/p[2]/span/span/span/a/img').get_attribute('src')\n",
    "            except:\n",
    "                try:\n",
    "                    imagen = driver.find_element_by_xpath('//*[@id=\"dapics\"]/div[2]/div/span/a/picture/img').get_attribute('src')\n",
    "                except:\n",
    "                    imagen = ''\n",
    "\n",
    "            names.append(name)\n",
    "            print(f'Name: {[True if len(names[-1])>1 else False]}, len: {len(names)}')\n",
    "\n",
    "            info.append(final)\n",
    "            print(f'Info: {[True if len(info[-1])>1 else False]}, len: {len(info)}')\n",
    "\n",
    "            images.append(imagen)\n",
    "            print(f'Imagen: {[True if len(images[-1])>1 else False]}, len: {len(images)}')\n",
    "\n",
    "            if len(names) != len(info) or len(names) != len(images):\n",
    "                print('Stop: lists length dont match')\n",
    "                break\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Dir with data\n",
    "    try:\n",
    "        os.mkdir('data')\n",
    "    except:\n",
    "        pass\n",
    "    os.chdir('data')\n",
    "    \n",
    "    \n",
    "    if save_txt == True:\n",
    "        # Save\n",
    "        results = open('names.txt','w', encoding=\"utf-8\")\n",
    "        for i in names:\n",
    "            results.write(str(i))\n",
    "            results.write('\\n')\n",
    "        results.close()\n",
    "\n",
    "        # Save\n",
    "        results = open('info.txt','w', encoding=\"utf-8\")\n",
    "        for i in info:\n",
    "            results.write(str(i))\n",
    "            results.write('\\n')\n",
    "        results.close()\n",
    "\n",
    "        # Save\n",
    "        results = open('links.txt','w', encoding=\"utf-8\")\n",
    "        for i in links:\n",
    "            results.write(str(i))\n",
    "            results.write('\\n')\n",
    "        results.close()\n",
    "\n",
    "        # Save\n",
    "        results = open('images.txt','w', encoding=\"utf-8\")\n",
    "        for i in images:\n",
    "            results.write(str(i))\n",
    "            results.write('\\n')\n",
    "        results.close()\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(list(zip(names,info,links,images)), columns =['names','info','links','images'])\n",
    "\n",
    "    # Descarga\n",
    "    df.to_csv('results.csv',index=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2644e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ CSV\n",
    "os.chdir('C:/Users/Felipe/Desktop/Proyectos/Weed/Data3')\n",
    "df = pd.read_csv('results.csv')\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].astype(str)\n",
    "    \n",
    "#Info into list\n",
    "info = list(df['info'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c454cc4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic / Breeders Info\n",
      "Cataract Kush is an indica variety from DNA Genetics and can be cultivated indoors (where the plants will need a flowering time of ±60 days) and outdoors. DNA Genetics' Cataract Kush is a THC dominant variety and is/was also available as feminized seeds.\n",
      "DNA Genetics' Cataract Kush Description\n",
      "This is the combination of two known winners, LA Confidential and OG Kush.\n",
      "\n",
      "She finishes in 8-9 weeks and has blankets of crystals! The Cataract Kush looks almost grey-black when cured.\n",
      "The flavor is LA dominate with the OG Kush coming thru in the exhale. The nugs look OG with LA density.\n",
      "This is the perfect combination of these two strains and the high is VERY strong!\n",
      "\n",
      "The effect is good for pain, eating and sleep disorders. Most describe Catract as a \"creeper\" high that keeps on building long after you stop smoking!\n",
      "This strain has been years in the making and is NOT recomended for the light weight smoker!!\n",
      "\n",
      "Above average yields and dense frosty nugs are easily achieved by the novice as well as seasond growers. After you experience the Cataract Kush you'll think you have cataracts!!!Cataract Kush from DNA Genetics Seeds is available as regular and feminized seeds. In 7 seedbanks, we found 14 offers between EUR 28.64 for 3 feminized seeds and EUR 80.00 for 13 regular seeds. If you are looking to buy Cataract Kush Cannabis Seeds from DNA Genetics Seeds somewhere - have a look to our Cataract Kush Price Comparison page with all current offers from all the connected seedbanks and shops - or visit one of the following tested, trustworthy and recommended seed-shops directly to check out their current Cataract Kush offers: Linda Seeds | Linda Semilla, Herbies Head Shop, Oaseeds, Canna-Seed Seed Shop, Cannapot Hanfshop, PEV Seeds Bank and canna-seed.com.\n"
     ]
    }
   ],
   "source": [
    "i = random.randint(0, len(info))\n",
    "print(info[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a799c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(name):\n",
    "    lista_names = list(df['names'].values)\n",
    "    if name in lista_names:\n",
    "        return name\n",
    "    \n",
    "    mejor_match, puntaje = process.extractBests(name.strip(), lista_names, scorer=fuzz.token_set_ratio)[0]\n",
    "    return print(f'No se encontro el nombre, tal vez quiciste decir: {mejor_match}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "55a10ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similars(name):\n",
    "\n",
    "    name = 'Kush Kush'\n",
    "    top_n = 3\n",
    "\n",
    "    info_cleaned = [i.replace('\\n','') for i in info]\n",
    "\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    indice_interes = list(df['names'].values).index(name)\n",
    "\n",
    "    doc_query = nlp(info_cleaned[indice_interes])\n",
    "\n",
    "    best_sim = [0]*top_n\n",
    "    indices = []\n",
    "\n",
    "    for i,inf in enumerate(info_cleaned):\n",
    "\n",
    "        doc_key = nlp(inf)\n",
    "        sim = doc_query.similarity(doc_key)\n",
    "\n",
    "        for t in range(top_n):\n",
    "            if sim > best_sim[t] and sim < 1:\n",
    "                best_sim[t] = sim\n",
    "                indices.append(i)\n",
    "\n",
    "    print(f'QUERY INFO:\\n {name} \\n {df[\"links\"][indice_interes]} \\n {df[\"info\"][indice_interes]} \\n')\n",
    "    print(f'TOP {top_n} FOUND INFO:')\n",
    "    for i,x in enumerate(indices):\n",
    "        print(f'----------- NUMBER {i} ----------- ')\n",
    "        print(df['names'][x], '\\n')\n",
    "        print(df['info'][x], '\\n')\n",
    "        print(df['links'][x], '\\n')\n",
    "        print(f'SIMILARITY: {best_sim[i]} \\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "611cee58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontro el nombre, tal vez quiciste decir: Kush Kush\n"
     ]
    }
   ],
   "source": [
    "get_name('Kush Magic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02b5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\AppData\\Local\\Temp\\ipykernel_18540\\3462037353.py:20: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  sim = doc_query.similarity(doc_key)\n"
     ]
    }
   ],
   "source": [
    "get_similars('Kush Kush')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
